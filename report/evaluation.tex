To perform this evaluation, a 10-fold cross-validation is performed in order to assess the decision tree’s accuracy.
Using the cross-validation an average error of the ten estimates is 10\% was discovered.

Having the 10-fold cross validation calculated on the training set, the classified results
are used to generate a confusion matrix.
To be more specific, the 10 predicted subsets are concatenated
and passed along with the actual target labels into a function responsible for the calculation of the confusion matrix.

From those matrix, it can be observed that the correct classifications for each class are on the matrix’s diagonal.
We can also state that, for the two sets of data, some similar emotion are confused.

\include*{confusion_matrix_clean}

For example, for those clean data, Sadness could be confused with Digust or Anger, which is logical when we can assume that sadness is a mix between those two emotions. 
Those confusions could happen in real faces recognitions for humans.
On the other hand Happiness seems to be the well recognised emotion, but we will
analyse Average Recall and Precision Rates for clean dataset for more details. 


\include*{recall_and_precision_rates_clean}

For the calculation of the precision and the recall rates per class, two formulas have been used.
Those formulas use information from the confusion matrix to calculate those two rates.

For the clean data set, it's clear that the well recognised emitions are happiness and surpise, with higher rates of F1 measure. 
We can also conclude sadness is less recogniseable than other emotions.


average classification rate:
71.6\%
 
\include*{confusion_matrix_noisy}

The main difference for the noisy data is that the diagonal of the matrix show less matches than the clean data set, but stay the main recognition for the emotions.
We can still observe some confusions between labels, especialluy between disgust sadness and anger, and the tendances that we state for clean data set remain the same (recognition of surprise and happinness).


\include*{recall_and_precision_rates_noisy}

The noisy data set confirm the results made on clean data set, and clearly show an higher recognition for happiness and suprised. However, even if sadness still shows a low F1 measure, anger have a lower measure than all the others. This can be explained by the fact that anger and sadness can be confused in the real world, which is closer to noisy data. 


average classification rate:
60.6\%


CONCLUSION OF EVALUATION

We can see that when using both strategies to determine the class, Class 4 (happiness) seems to have higher recognition, and Class 5 (sadness) is what gets recognised least and is mostly confused with anger. This may also be due to the fact that we have plenty of data for class 4 and not so much for class 5.
From the performance analysis of noisy data, we can see that again class 4 is recognised with high precision when using balanced tree classification and class 2 (disgust) is recognised with more precision when using length based classification. Both strategies have difficulties in identifying class 1 and class 5.

TITLE: CLASSIFICATION RATE

Finally the classification rate show that with clean data we can classify more emotions than with noisy data, which could seam logical. 
We can also state the tree are well trained beacuse we have more than 60\% for each data set wich are good rates. 




