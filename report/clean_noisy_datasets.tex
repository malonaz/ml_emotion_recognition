Decision Trees are built using datasets and as such, their precision and accuracy rely heavily on the quality of the data.
Consequently, when fed noisy data with missing or wrongly detected attributes, decision trees need relatively more data to
perform at the same level as trees trained with clean datasets. Here the noisy dataset was equal to the clean dataset in magnitude, yet the quality of its data points
inferior in quality. This is a situation prone to overfitting and we must introduce pruning methods in order to disregard attributes
that are exhibited by noise rather than by examples themselves. Let's take a look at a the clean vs noisy Anger tree.

\begin{figure}[!ht]
\center
	\caption{Clean dataset - Anger}  
	\includegraphics[scale = 0.10]{graphs/clean_dataset/emotion1.pdf}
   \label{fig:cleandecisionTree1}
\end{figure}

\begin{figure}[!ht]
\center
	\caption{Noisy dataset - Anger}  
	\includegraphics[scale = 0.10]{graphs/noisy_dataset/emotion1.pdf}
   \label{fig:cleandecisionTree1}
\end{figure}



Here, there is a significant drop across all metrics when switching from the clean to the noisy dataset.
Anger in the clean dataset has an F\textsubscript{1} measure of 64.66\%, versus 27.96\% in the noisy dataset.
The accuracy almost halves when using the noisy data but taking a closer look at the metrics, we see that the precision
rate is the stronger culprit in such a low F\textsubscript{1} measure. This implies that the Anger tree is incorrectly claiming
data points as examples of anger. This may be explained by both poor quality and lack of data.

All emotions retain F\textsubscript{1} values that are proportionally lower to the clean dataset. 
Surprise emotion seems to be the easiest emotion to identify with only a slight decrease of F\textsubscript{1} value with noisy data.
Since noisy datasets are obtained from automated recognition systems, it seems that computers do a significantly better job
breaking down the facial muscle components of Happiness than they do breaking down Sadness or Anger. 
